# Hagidoop

## Objectifs
Comme l’objectif de ce projet est d’implanter le service HDFS (Hagidoop Distributed File System) avec les fonctionnalités suivantes : 
  - Découpage des fichiers en fragments. 
  - Stockage des fragments sur les noeuds du cluster. 
  - Copie d'un fichier du système de fichiers local dans le FS HDFS.
  - Copie d'un fichier du FS HDFS dans le FS local.
  - Suppression des fragments d'un fichier stocké dans HDFS,
  - de mettre en place un service Hagidoop permettant l'exécution répartie et parallèle des traitements Map,
  - de mettre en place la communication entre le démon (Worker) responsable de l'exécution des tâches Map et ses clients à l'aide de RMI,
  - d'implémenter la classe JobLauncher pour lancer un calcul parallèle en utilisant le modèle Map-Reduce.

## Utilisation 

Pour utiliser le projet, veuillez consulter le manuel d'utilisation.
